---
title: "Assignment #2"
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(stacks)            # for stacking models
library(naniar)            # for analyzing missing values
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(DALEX)             # for model interpretation
library(DALEXtra)          # for extension of DALEX
library(patchwork)         # for combining plots nicely
```

```{r data}
data("lending_club")
```


## Put it on GitHub!

[Here](https://github.com/alexdenzler/STAT494_site_Denzler) is my GitHub link.

## Modeling

We’ll be using the `lending_club` dataset from the `modeldata` library, which is part of `tidymodels`. The outcome we are interested in predicting is `Class`. And according to the dataset’s help page, its values are “either ‘good’ (meaning that the loan was fully paid back or currently on-time) or ‘bad’ (charged off, defaulted, of 21-120 days late)”. 

### **Tasks**

(@) Explore the data, concentrating on examining distributions of variables and examining missing values.

```{r}
lending_club %>% 
  ggplot(aes(x = funded_amnt)) +
  geom_density() + 
  facet_wrap(vars(Class))
```

```{r}
lending_club %>% 
  ggplot(aes(x = int_rate)) +
  geom_density() + 
  facet_wrap(vars(Class))
```

```{r}
lending_club %>% 
  ggplot(aes(x = annual_inc)) +
  geom_density() + 
  facet_wrap(vars(Class))
```


```{r}
lending_club %>% 
  ggplot(aes(x = addr_state, fill = Class)) +
  geom_bar(position = "fill")
```

```{r}
lending_club %>% 
  count(Class)
```
```{r}
lending_club %>% 
  group_by(addr_state) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count))
```



(@) Do any data cleaning steps that need to happen before the model is build. For example, you might remove any variables that mean the same thing as the response variable (not sure if that happens here), get rid of rows where all variables have missing values, etc.

```{r}
create_more_bad <- lending_club %>% 
  filter(Class == "bad") %>% 
  sample_n(size = 3000, replace = TRUE)

lending_club_mod <- lending_club %>% 
  bind_rows(create_more_bad)
```


(@) Split the data into training and test, putting 75% in the training data.

```{r}
set.seed(494) # for reproducability

lending_split <- initial_split(lending_club_mod,
                             prop = 0.75)
lending_train <- training(lending_split)
lending_test  <- testing(lending_split)
```


(@) Set up the recipe and the pre-processing steps to build a lasso model. Some steps you should take:

* Make all integer variables numeric (I’d highly recommend using `step_mutate_at()` or this will be a lot of code). We’ll want to do this for the model interpretation we’ll do later.
* Think about grouping factor variables with many levels.
* Make categorical variables dummy variables (make sure NOT to do this to the outcome variable).
* Normalize quantitative variables.


```{r}
lending_recipe <- recipe(Class ~ .,
                         data = lending_train) %>% 
  step_rm(acc_now_delinq, delinq_amnt) %>% 
  step_mutate_at(all_numeric(),
                 fn = ~as.numeric(.)) %>% 
  step_mutate(verification_status = 
                ifelse(verification_status == "Not_Verified", "Not_Verified", "Verified")) %>% 
  step_mutate(annual_inc =
              case_when(annual_inc <= 9875 ~ 10,
                        annual_inc > 9875   && annual_inc <= 40125  ~ 12,
                        annual_inc > 40125  && annual_inc <= 85525  ~ 22,
                        annual_inc > 85525  && annual_inc <= 163300 ~ 24,
                        annual_inc > 163300 && annual_inc <= 207350 ~ 32,
                        annual_inc > 207350 && annual_inc <= 518400 ~ 35,
                        annual_inc > 518400                         ~ 37)) %>%
  step_mutate(annual_inc = as.factor(annual_inc)) %>% 
  step_normalize(all_predictors(), -all_nominal()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

lending_recipe %>% 
  prep(lending_train) %>% 
  juice()
```

(@) Set up the LASSO model and workflow. We will tune the `penalty` parameter.

```{r}
lasso_lending_mod <- logistic_reg(mixture = 1) %>%
  set_engine("glmnet") %>% 
    set_args(penalty = tune()) %>% 
      set_mode("classification")

lasso_lending_mod

lending_workflow <- workflow() %>%
  add_recipe(lending_recipe) %>%
    add_model(lasso_lending_mod)

lending_workflow
```


(@) Set up the model tuning for the `penalty` parameter. Be sure to add the `control_stack_grid()` for the `control` argument so we can use these results later when we stack. Find the accuracy and area under the roc curve for the model with the best tuning parameter. Use 5-fold cv.

```{r}
set.seed(494)

lending_cv <- vfold_cv(lending_train, v = 5)

lending_lasso_pen_grid <- grid_regular(penalty(), levels = 10)

ctrl_grid <- control_stack_grid()

lending_lasso_tune <- lending_workflow %>% 
  tune_grid(resamples = lending_cv,
            grid = lending_lasso_pen_grid,
            control = ctrl_grid)

best_param <- lending_lasso_tune %>% 
  select_best(metric = "penalty")

lending_lasso_final_wf <- lending_workflow %>% 
  finalize_workflow(best_param)

lending_lasso_final_mod <- lending_lasso_final_wf %>% 
  fit(data = lending_train)
```

```{r}
lasso_explain <- 
  explain_tidymodels(
    model = lending_lasso_final_mod,
    data = lending_train %>% select(-Class), 
    y = lending_train %>%  pull(Class),
    label = "lasso"
  )
```



(@) Set up the recipe and the pre-processing steps to build a random forest model. You shouldn’t have to do as many steps. The only step you should need to do is making all integers numeric.

```{r}
ranger_recipe <- recipe(Class ~ .,
                         data = lending_train) %>% 
  step_rm(acc_now_delinq, delinq_amnt) %>% 
  step_mutate_at(all_numeric(),
                 fn = ~as.numeric(.)) %>% 
  step_mutate(verification_status = 
                ifelse(verification_status == "Not_Verified", "Not_Verified", "Verified")) %>% 
  step_mutate(annual_inc =
              case_when(annual_inc <= 9875                          ~ 10,
                        annual_inc > 9875   && annual_inc <= 40125  ~ 12,
                        annual_inc > 40125  && annual_inc <= 85525  ~ 22,
                        annual_inc > 85525  && annual_inc <= 163300 ~ 24,
                        annual_inc > 163300 && annual_inc <= 207350 ~ 32,
                        annual_inc > 207350 && annual_inc <= 518400 ~ 35,
                        annual_inc > 518400                         ~ 37)) %>%
  step_mutate(annual_inc = as.factor(annual_inc))
```

(@) Set up the random forest model and workflow. We will tune the `mtry` and `min_n` parameters and set the number of trees, `trees`, to 100 (otherwise the next steps take too long).

```{r}
ranger_spec <- rand_forest(mtry = tune(),
                           min_n = tune(),
                           trees = 100) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

ranger_spec

ranger_workflow <- workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec)

ranger_workflow
```

(@) Set up the model tuning for both the `mtry` and `min_n` parameters. Be sure to add the `control_stack_grid()` for the control argument so we can use these results later when we stack. Use only 3 levels in the grid. For the `mtry` parameter, you need to put `finalize(mtry(), lending_training %>% select(-Class))` in as an argument instead of just `mtry()`, where `lending_training` is the name of your training data. This is because the `mtry()` grid will otherwise have unknowns in it. This part can take a while to run.

```{r}
set.seed(494)

lending_rf_mtry_grid <- grid_regular(finalize(mtry(), lending_train %>% select(-Class)),
                                     levels = 3) 

ctrl_res <- control_stack_grid()

ranger_cv <- ranger_workflow %>% 
  fit_resamples(lending_cv,
                control = ctrl_res)

collect_metrics(ranger_cv)
```










