---
title: "Assignment #3"
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
# SEE modeldata package for new datasets
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(stacks)            # for stacking models
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(DALEX)             # for model interpretation  
library(DALEXtra)          # for extension of DALEX
library(patchwork)         # for combining plots nicely
library(dbplyr)            # for SQL query "cheating" - part of tidyverse but needs to be loaded separately
library(mdsr)              # for accessing some databases - goes with Modern Data Science with R textbook
library(RMySQL)            # for accessing MySQL databases
library(RSQLite)           # for accessing SQLite databases

#mapping
library(maps)              # for built-in maps
library(sf)                # for making maps using geom_sf
library(ggthemes)          # Lisa added - I like theme_map() for maps :)

#tidytext
library(tidytext)          # for text analysis, the tidy way!
library(textdata)          
library(reshape2)
library(wordcloud)         # for wordcloud
library(stopwords)
```

## Put it on GitHub!

[Here](https://github.com/alexdenzler/STAT494_site_Denzler) is my GitHub link.


## Local Interpretable Machine Learning

We will use the King County housing data.

```{r}
data("house_prices")

# Create log_price and drop price variable
house_prices <- house_prices %>% 
  mutate(log_price = log(price, base = 10)) %>% 
  # make all integers numeric ... fixes prediction problem
  mutate(across(where(is.integer), as.numeric)) %>% 
  select(-price)
```


### Part 1

  Choose 3 new observations and do the following for each observation:
  * Construct a break-down plot using the default ordering. Interpret the resulting graph. Which variables contribute most to each observation’s prediction?
  * Construct a SHAP graph and interpret it. Does it tell a similar story to the break-down plot?
  * Construct a LIME graph (follow my code carefully). How close is each original prediction to the prediction from the local model? Interpret the result. You can also try using fewer or more variables in the local model than Lisa used in the example.
  
  
```{r}
set.seed(494)

house_split <- initial_split(house_prices, 
                             prop = .75)
house_train <- training(house_split)
house_test <- testing(house_split)

house_ranger_recipe <- 
  recipe(formula = log_price ~ ., 
         data = house_train) %>% 
  step_date(date, 
            features = "month") %>% 
  update_role(all_of(c("id",
                       "date")),
              new_role = "evaluative")

house_ranger_spec <- 
  rand_forest(mtry = 6, 
              min_n = 10, 
              trees = 200) %>% 
  set_mode("regression") %>% 
  set_engine("ranger")

house_ranger_workflow <- 
  workflow() %>% 
  add_recipe(house_ranger_recipe) %>% 
  add_model(house_ranger_spec) 

set.seed(494)
house_ranger_fit <- house_ranger_workflow %>% 
  fit(house_train)
```
  
  
```{r}
house_rf_explain <- 
  explain_tidymodels(
    model = house_ranger_fit,
    data = house_train %>% select(-log_price), 
    y = house_train %>%  pull(log_price),
    label = "Random Forest"
  )
```
  
```{r}
set.seed(494)
new_obs1 <- house_test %>% slice(4239)
new_obs2 <- house_test %>% slice(294)
new_obs3 <- house_test %>% slice(3)

10^(new_obs1$log_price)
10^(new_obs2$log_price)
10^(new_obs3$log_price)
```
  
#### Break-Down Plots
  
```{r}
house_pp_rf1 <- predict_parts(explainer = house_rf_explain,
                       new_observation = new_obs1,
                       type = "break_down")

house_pp_rf2 <- predict_parts(explainer = house_rf_explain,
                       new_observation = new_obs2,
                       type = "break_down")

house_pp_rf3 <- predict_parts(explainer = house_rf_explain,
                       new_observation = new_obs3,
                       type = "break_down")

plot(house_pp_rf1)
plot(house_pp_rf2)
plot(house_pp_rf3)
```

  * The average log price remains the same across all observations, as it is the average log price when applied to all of the training data. This log price is 5.665, or \$462,381. We  see that holding constant at 6 affects the overall average price the most, and decreases the log price by 0.03, or \$30,861.90. The predicted log price for this observation is 5.577, or \$377,572.20.

  * The second plot shows us that fixing our latitude at 47.6272 increases the average log price by 0.113, or \$137,410.10. We also see that holding this latitude constant affects the price the most. Finally, the predicted log price for this observation is 5.862, or \$727,779.80.

  * The third plot shows us that fixing our latitude at 47.5123 decreases the log price by 0.069, or \$67,923.70. Holding this latitude constant affects the predicted price the most. This predicted log price is 5.46, or \$288,403.20.


#### Shapley Additive Explanationss (SHAP) Plots

```{r, cache=TRUE}
house_rf_shap1 <-predict_parts(explainer = house_rf_explain,
                        new_observation = new_obs1,
                        type = "shap",
                        B = 10
)

house_rf_shap2 <-predict_parts(explainer = house_rf_explain,
                        new_observation = new_obs2,
                        type = "shap",
                        B = 10
)

house_rf_shap3 <-predict_parts(explainer = house_rf_explain,
                        new_observation = new_obs3,
                        type = "shap",
                        B = 10
)

plot(house_rf_shap1)
plot(house_rf_shap2)
plot(house_rf_shap3)
```


  * The first SHAP plot shows a similar effect to the first break-down plot, where grade is the highest contributing variable, however this time it is in a negative way. The second and third SHAP plots both show that latitude is the highest contributing variable, which is in accordance with the break-down plots, this time both affecting the predicted price in the same way as the break-down plots. 
  

#### Local Interpretable Model-Agnostic Explanation (LIME) Plots

```{r}
set.seed(494)

model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer

house_lime_rf1 <- predict_surrogate(explainer = house_rf_explain,
                                    new_observation = new_obs1 %>%
                                    select(-log_price), 
                                    n_features = 5,
                                    n_permutations = 1000,
                                    type = "lime")

house_lime_rf2 <- predict_surrogate(explainer = house_rf_explain,
                                    new_observation = new_obs2 %>%
                                    select(-log_price), 
                                    n_features = 5,
                                    n_permutations = 1000,
                                    type = "lime")

house_lime_rf3 <- predict_surrogate(explainer = house_rf_explain,
                                    new_observation = new_obs3 %>%
                                    select(-log_price), 
                                    n_features = 5,
                                    n_permutations = 1000,
                                    type = "lime")

house_lime_rf1 %>% 
  select(model_r2, model_prediction, prediction) %>% 
  distinct()

house_lime_rf2 %>% 
  select(model_r2, model_prediction, prediction) %>% 
  distinct()

house_lime_rf3 %>% 
  select(model_r2, model_prediction, prediction) %>% 
  distinct()
```

```{r}
plot(house_lime_rf1) +
  labs(x = "Variable")

plot(house_lime_rf2) +
  labs(x = "Variable")

plot(house_lime_rf3) +
  labs(x = "Variable")
```


  * Plot 1 shows us that the predicted log price is about 5.577, and that grade is once again the most important in the local model. This model also performs quite poorly, as the explanation fit is only 0.11. This is the exact prediction (to three digits) that the original model had.
  
  * Plot 2 shows us that the predicted log price is about 5.86, and that the living room area and latitude are the most important in the local model, albeit in opposite ways. This model performs better than the first, as the explanation fit is 0.45. This is the exact prediction (to two digits) as the original model.
  
  * Plot 3 shows us that the predicted log price is about 5.46, and that the grade is the most important to the local model. This model performs the worst out of the three, as the explanation fit is only 0.1. This is the exact prediction (to two digits) as the original model. 


### Part 2
  
  Describe how you would use the interpretable machine learning tools we’ve learned (both local and global) in future machine learning projects? How does each of them help you?
  
  * These methods provide a helpful alternative to a simple variable importance plot, as we are able to identify variable importance on the level of individual observations. We are able to see why each observation contains the result that it does. The break-down plot method allows us to see how the entire training dataset is affected when we apply a certain model to it. The SHAP plots allow us to see how each variable contributes if we change the order of the variables (in this assignment, the contribution changes because the random forest model is not additive). Through this, we are able to see how true the effect is through the boxplots on top of the SHAP plot. Finally, the LIME plots allow us to see variable importance in conjunction with model performance, which gives us more insight into how trustworthy our result is.
  

## SQL 

I will use the `airlines` data from the SQL database that Lisa used in the example in the tutorial.

**Tasks**

  1. Create a SQL chunk and an equivalent R code chunk that does the following: for 2017, for each airport (with its name, not code), and month find the total number of departing flights, the average distance of the flight, and the proportion of flights that arrived more than 20 minutes late. In the R code chunk, write this out to a dataset.
  
```{r}
con_air <- dbConnect_scidb("airlines")
```


```{sql connection=con_air}
DESCRIBE flights
```

```{sql connection=con_air}
DESCRIBE airports
```


```{r}
late_flights_over20 <- tbl(con_air, "flights") %>% 
  group_by(origin, month) %>% 
  filter(year == 2017) %>%
  summarize(tot_depart = n(),
            avg_dist = mean(distance),
            prop_late_over20 = mean(arr_delay > 20)) %>% 
  inner_join(tbl(con_air, "airports"),
             by = c("origin" = "faa")) %>% 
  select(name, month, tot_depart, avg_dist, prop_late_over20)

late_flights_over20
```


```{sql connection=con_air, eval=FALSE}
SELECT
  year,
  arr_delay,
  origin,
  COUNT(*) AS n_flights,
  AVG(arr_delay > 20) AS prop_late_over20,
  AVG(distance) AS avg_dist
  FROM flights
  WHERE year = 2017
  GROUP BY origin, month
  INNER JOIN airports AS a
    ON (flights.origin = a.faa)
  ORDER BY year, prop_late_over20 DESC;
```
  
  * With the dataset you wrote out, create a graph that helps illustrate the “worst” airports in terms of late arrivals.
  
```{r}
late_flights_over20 %>% 
  ggplot(aes(x = mean(prop_late_over20),
             y = fct_reorder(name, prop_late_over20, median))) +
  geom_col(fill = "lightblue") +
  scale_x_continuous(expand = c(0,0), 
                     labels = scales::percent) +
  labs(x = NA,
       y = NA,
       title = "Which airlines had the largest % of flights that \nwere more than 20 minutes late from 2010-2017?")
```
  

## Function Friday

### `geom_sf()` Tasks

```{r}
states <- st_as_sf(maps::map("state", 
                             plot = FALSE, 
                             fill = TRUE))

counties <- st_as_sf(maps::map("county", 
                               plot = FALSE, 
                               fill = TRUE))
```

```{r}
states <- states %>%
  mutate(area = as.numeric(st_area(states)))
head(states)
```

1. Change the color scheme of the map from the default blue (one option could be viridis).

```{r}
ggplot(data = states) +
  geom_sf(aes(fill = area)) +
  scale_fill_gradient(low = "blue", high = "red") +
  coord_sf(xlim = c(-127, -63), 
           ylim = c(24, 51), 
           expand = FALSE)
```

2. Add a dot (or any symbol you want) to the centroid of each state.

```{r}
centroids <- states %>% 
  mutate(centroid = st_centroid(geom))
centroids
```


```{r, eval=FALSE}
ggplot() +
  geom_sf(data = states, aes(fill = area)) +
  scale_fill_gradient(low = "blue", high = "red") +
  coord_sf(xlim = c(-127, -63), 
           ylim = c(24, 51), 
           expand = FALSE) +
  geom_point(data = centroids, aes(x = centroid[1], y = centroid[2]))
```


3. Add a layer onto the map with the counties.

```{r, eval=FALSE}
ggplot() +
  geom_sf(data = counties, fill = NA, color = "black") +
  geom_sf(data = states, aes(fill = area)) +
  scale_fill_gradient(low = "blue", high = "red") +
  coord_sf(xlim = c(-127, -63), 
           ylim = c(24, 51), 
           expand = FALSE) #+
  #geom_point(data = centroids, aes(x = centroid[1], y = centroid[2]))
```


4. Change the coordinates of the map to zoom in on your favorite state.

```{r, eval=FALSE}
ggplot() +
  #geom_sf(data = counties, fill = NA, color = "black") +
  geom_sf(data = states, aes(fill = area)) +
  scale_fill_gradient(low = "blue", high = "red") +
  coord_sf(xlim = c(-127, -63), 
           ylim = c(24, 51), 
           expand = FALSE) #+
  #geom_point(data = centroids, aes(x = centroid[1], y = centroid[2]))
```














